# -*- coding: utf-8 -*-
"""инвестиции.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tTF5uHpnL9pCWMoSWTszelV7CZ8FEIpy

Получаем figi для дальнейшей работы
"""

# Импорт библиотек
import pandas as pd  # Библиотека pandas для работы с данными в формате DataFrame
import numpy as np   # Библиотека numpy для работы с массивами и матрицами
import seaborn as sns  # Библиотека seaborn для визуализации данных
import matplotlib.pyplot as plt  # Библиотека matplotlib для построения графиков
import requests   # Библиотека requests для выполнения HTTP-запросов

# Установка токена аутентификации для доступа к API
authToken = 't.i3u0rK6kEv3SPH391u70UDxTCsUqaOBVzLOm6tWgijT_SQLV9GbEQljT41QvjnA5Hu7wu_CHxJSz1bd2IfaYsg'

# Заголовки для HTTP-запроса
headers = {
    'accept': 'application/json',
    'Content-Type': 'application/json',
    'Authorization': f'Bearer {authToken}'  # Аутентификационный токен
}

# JSON-данные для запроса
json_data = {
    "query": "Ozon",  # Поисковый запрос (название инструмента)
    "instrumentKind": "INSTRUMENT_TYPE_UNSPECIFIED",  # Тип инструмента (неуказанный)
    "apiTradeAvailableFlag": True  # Флаг доступности торговли через API (включен)
}

# Выполнение POST-запроса к API для поиска инструмента по запросу
response = requests.post(
    'https://invest-public-api.tinkoff.ru/rest/tinkoff.public.invest.api.contract.v1.InstrumentsService/FindInstrument',
    headers=headers,  # Заголовки для запроса
    json=json_data    # JSON-данные для запроса
)

# Преобразование ответа в формат JSON
data = response.json()

# Преобразование данных о инструментах в формат DataFrame с помощью pandas
df = pd.json_normalize(data['instruments'])

# Вывод определенных столбцов DataFrame (figi, ticker, name, instrumentType)
df[['figi', 'ticker', 'name',  'instrumentType']]

"""Получаем свечи"""

import requests  # Импорт библиотеки requests для выполнения HTTP-запросов
import pandas as pd  # Импорт библиотеки pandas для работы с данными в формате DataFrame

# JSON-данные, которые будут отправлены в запросе
json_data = {
    "from": "2023-10-08T00:00:00.866Z",  # Начальная дата и время для получения данных
    "to": "2023-11-08T00:00:00.866Z",    # Конечная дата и время для получения данных
    "interval": "CANDLE_INTERVAL_DAY",   # Интервал свечей (день)
    "instrumentId": "BBG00Y91R9T3"       # Идентификатор финансового инструмента
}

# Выполнение POST-запроса к API для получения свечей с заданными параметрами
response = requests.post(
    'https://invest-public-api.tinkoff.ru/rest/tinkoff.public.invest.api.contract.v1.MarketDataService/GetCandles',
    headers=headers,  # Заголовки для запроса (не показаны в примере)
    json=json_data    # JSON-данные для запроса
)

# Преобразование ответа в формат JSON
data = response.json()

# Вывод свечей (данных) из ответа
print(data['candles'])

# Преобразование данных о свечах в формат DataFrame с помощью pandas
df = pd.json_normalize(data['candles'])

# Возврат DataFrame с данными о свечах
df

"""Рисуем свечки"""

import plotly.graph_objects as go
from datetime import datetime

# Создание графика свечей (Candlestick chart) с использованием данных из DataFrame
fig = go.Figure(data=[go.Candlestick(x=df['time'],
                open=df['open.units'],
                high=df['high.units'],
                low=df['low.units'],
                close=df['close.units'])])

# Отображение графика
fig.show()

# Создание пустого списка для хранения цен
prices = []

# Проход по каждой свече в данных
for candle in data['candles']:
    # Получение цены открытия из свечи и преобразование в строку
    # Формирование строки с ценой, объединяя целую и дробную часть цены с помощью точки
    # Добавление строки с ценой в список prices
    prices.append(str(candle['open']['units']) + "." + str(candle['open']['nano'])[:2])

# Вывод списка цен
print(prices)

import tensorflow as tf  # Импорт TensorFlow для работы с нейронными сетями
from sklearn.preprocessing import MinMaxScaler  # Импорт MinMaxScaler из библиотеки scikit-learn для масштабирования данных

prices_array = np.array(prices[:-1])  # Преобразование цен в массив numpy

# Масштабирование значений
scaler = MinMaxScaler(feature_range=(0, 1))  # Создание объекта MinMaxScaler для масштабирования данных
prices_scaled = scaler.fit_transform(prices_array.reshape(-1, 1))  # Масштабирование данных

# Создание набора данных для обучения
def create_dataset(dataset, time_steps=1):
    X, y = [], []
    for i in range(len(dataset)-time_steps):
        X.append(dataset[i:(i+time_steps), 0])
        y.append(dataset[i + time_steps, 0])
    return np.array(X), np.array(y)

time_steps = 3  # Шаги времени для прогнозирования
X_train, y_train = create_dataset(prices_scaled, time_steps)  # Создание датасета для обучения

# Изменение формы в трехмерный массив
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# Создание модели нейронной сети
model = tf.keras.Sequential([
    tf.keras.layers.LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    tf.keras.layers.LSTM(units=50, return_sequences=False),
    tf.keras.layers.Dense(units=1)
])

results = []  # Список для хранения результатов

optimizers = ['adam', 'adadelta', 'nadam']  # Список оптимизаторов

for optimizer in optimizers:
    # Компиляция модели
    model.compile(optimizer=optimizer, loss='mean_squared_error')

    # Обучение модели
    model.fit(X_train, y_train, epochs=100, batch_size=1)

    # Прогнозирование цен на следующие 3 дня
    test_input = prices_scaled[-time_steps:].reshape((1, time_steps, 1))
    predicted_prices_scaled = model.predict(test_input)

    predicted_prices = scaler.inverse_transform(predicted_prices_scaled)

    def calculate_percentage_difference(x, y):
        avg = (x + y) / 2
        difference = abs(x - y)
        percentage_difference = (difference / avg) * 100
        return round(percentage_difference, 2)

    # Вывод информации о модели и прогнозе
    print(f'Модель: {optimizer}\nПредсказанная цена: {"{:.2f}".format(float(predicted_prices[0][0]))}\nИстинное значение: {float(prices[-1])}\nПроцент расхождения: {calculate_percentage_difference(float(predicted_prices[0][0]), float(prices[-1]))}')

    # Создание словаря с результатами
    result = {
        'optimizer': optimizer,
        'predicted_price': float(predicted_prices[0][0]),
        'true_price': float(prices[-1]),
        'difference': calculate_percentage_difference(float(predicted_prices[0][0]), float(prices[-1]))
    }

    results.append(result)  # Добавление результатов в список

output_json = {'results': results}  # Создание JSON-структуры с результатами

df = pd.json_normalize(output_json['results'])  # Преобразование результатов в DataFrame

df  # Вывод DataFrame

results = output_json['results']

# Найти наименьший процент расхождения
min_difference = min(result['difference'] for result in results)

# Найти элемент с наименьшим процентом расхождения
min_result = next(result for result in results if result['difference'] == min_difference)

# Вывести информацию о наименьшем проценте расхождения
print("Модель с наименьшим процентом расхождения:")
print(f"Оптимизатор: {min_result['optimizer']}")
print(f"Предсказанная цена: {min_result['predicted_price']}")
print(f"Истинное значение: {min_result['true_price']}")
print(f"Процент расхождения: {min_result['difference']}")